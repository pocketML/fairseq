--fp16
--ddp-backend=legacy_ddp
--restore-file roberta.large/model.pt
--reset-optimizer
--reset-dataloader
--reset-meters
--no-epoch-checkpoints
--no-last-checkpoints
--no-save-optimizer-state
--best-checkpoint-metric accuracy
--maximize-best-checkpoint-metric
--init-token 0
--bpe gpt2
--arch roberta_large
--max-positions 512
--dropout 0.1
--attention-dropout 0.1
--weight-decay 0.01
--criterion sentence_ranking
--num-classes 5
--optimizer adam
--adam-betas '(0.9,0.98)'
--adam-eps 1e-06
--clip-norm 0.0
--lr-scheduler polynomial_decay
--lr 1e-05
--warmup-updates 150
--total-num-update 3000
--batch-size 8
--max-update 3000
--log-format simple
--log-interval 25
--seed 1
--user-dir examples/roberta/commonsense_qa